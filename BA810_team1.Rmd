---
title: 'Team 1: Framingham Heart Study CHD Predictions'
author: "Kaiyu Wang, Chinar Boolchandani, Urvashi Tripathi, Chun Zhou, Ryan Nie, Zhenyang Gai"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## I.Setup
```{r}
#install.packages('readr', dependencies = TRUE, repos='http://cran.rstudio.com/')
library(readr)
library(data.table)
library(ggplot2)
library(dplyr)
library(reshape2)
library(glmnet)
library(ROCR)
library(pROC)
library(PRROC)
library(lattice)
library(caret)
library(e1071)
library(randomForest) 

CHD <-fread("framingham.csv")
```

## II.Clean Data

### 1. Summary
```{r}
summary(CHD)
```

### 2. Replace NA
```{r}
education_median<-median(CHD$education,na.rm=TRUE)
CHD[is.na(education),education:=education_median]

cigsPerDay_median<-median(CHD$cigsPerDay,na.rm=TRUE)
CHD[is.na(cigsPerDay),cigsPerDay:=cigsPerDay_median]

BPMeds_median<-median(CHD$BPMeds,na.rm=TRUE)
CHD[is.na(BPMeds),BPMeds:=BPMeds_median]

totChol_median<-median(CHD$totChol,na.rm=TRUE)
CHD[is.na(totChol),totChol:=totChol_median]

glucose_median<-median(CHD$glucose,na.rm=TRUE)
CHD[is.na(glucose),glucose:=glucose_median]

heartRate_median<-median(CHD$heartRate,na.rm=TRUE)
CHD[is.na(heartRate),heartRate:=heartRate_median]

BMI_median<-median(CHD$BMI,na.rm=TRUE)
CHD[is.na(BMI),BMI:=BMI_median]
```

### 3. Rename Column 1
```{r}
colnames(CHD)[1] <- 'is_male'
```

## III.EDA
### 1. Distribution of Ten Year Risk of CHD
```{r}
count1 <- length(which(CHD$TenYearCHD == 1))
count1
count2 <- length(which(CHD$TenYearCHD == 0))
count2
```

```{r}
common_theme <- theme(plot.title = element_text(hjust = 0.5, face = "bold"))

ggplot(data = CHD, aes(x = factor(TenYearCHD), 
                          y = prop.table(stat(count)), 
                          fill = factor(TenYearCHD),
                          label = scales::percent(prop.table(stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_x_discrete(labels = c("no risk", "risk"))+
    scale_y_continuous(labels = scales::percent)+
    labs(x = 'Disease Prevalence', y = 'Percentage',fill='TenYearCHD') +
    ggtitle("Distribution of Ten Year Risk of CHD") +
    common_theme
```

### 2. Distribution of Percentage of CHD with Age
```{r}
CHD$agec <- 
  cut(CHD$age, breaks = c(30,35,40,45,50,55,60,65,70),
      labels = c("30-35","35-40","40-45","45-50","50-55","55-60","60-65","65-70"))
  
d <- CHD %>% group_by(agec) %>% summarise(perc = mean(TenYearCHD=='1'))
d$perc_r <- round(d$perc,2)*100
d$perc_r <- interaction(d$perc_r, "%", sep = "")
d

ggplot(d,aes(x=agec,y=perc)) + 
geom_col()+
scale_y_continuous(labels=scales::percent)+
geom_text(aes(label = perc_r), vjust = -0.5)+
labs(x='Age Group',y='Percentage')+
ggtitle("Distribution of Percentage of CHD with Age")+
common_theme
```

### 3. Histogram of CHD with Age and Gender
```{r}
#cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", #"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
CHD_1 <- CHD[ CHD$TenYearCHD=='1',]
CHD_1$is_male[CHD_1$is_male == 0] <- "female"
CHD_1$is_male[CHD_1$is_male == 1] <- "male"
ggplot(data=CHD_1,aes(age,fill=is_male))+
  geom_bar(position = position_dodge(width = 0.5))+
#  scale_fill_brewer(palette=cbPalette)+
  labs(x = "Age in years",y = "CHD count")+
  ggtitle("Distribution of CHD with age and gender")+
  common_theme
```

### 4. Probability of Disease in Smokers
```{r}
d2 <- CHD %>% group_by(currentSmoker) %>% summarise(perc = mean(TenYearCHD=='1'))
d2
```

### 5. Line Chart of Percentage of CHD with Age and Gender
```{r}
d3 <- CHD %>% group_by(agec,factor(is_male)) %>% summarise(perc = mean(TenYearCHD=='1'))
d3
ggplot() + 
geom_line(data=d3,aes(agec, perc,group =`factor(is_male)`,color =`factor(is_male)` ))+
scale_y_continuous(labels=scales::percent)+
labs(x='Age Group',y='Percentage',color='Gender' )+
ggtitle("Distribution of Percentage of CHD with Age and Gender")+
common_theme
```

### 6. Pairwise Correlation Analysis
```{r}
a <- CHD[,c(1,3,5,7,9,11,13,15)]
pairs(a, col = "coral",main = "Pairwise Correlation Analysis")
```

### 7. Histogram of Cigarettes per Day
```{r}
ggplot(data = CHD, aes(BMI,glucose,color = age)) + geom_point(fill = "blue") 
ggplot(data = CHD, aes(x = cigsPerDay, color = education)) + geom_histogram(color="black", fill="pink")+labs(x='Cigarettes per day', y = 'Count of people')
#+  + geom_vline(aes(intercept=mean(cigsPerDay)), color="blue", linetype="dashed", size=12)
```

### 8. Correlation Heatmap
```{r}
CHD<-subset(CHD,select=-c(17))
cormat <- round(cor(CHD),2)
melted_cormat <- melt(cormat)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
common_theme+
geom_tile()+
scale_fill_gradient2(low = "green", high = "blue",  
   midpoint = 0, limit = c(-1,1), 
   name="Correlation")
```

## IV.Machine Learning

### 1. Split Dataset
```{r}
library(fastDummies)
CHD<-dummy_cols(CHD,select_columns=c('is_male','education','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','TenYearCHD'),remove_first_dummy=TRUE,remove_selected_columns=TRUE)
```

```{r}
names(CHD)[15] <- 'TenYearCHD'
names(CHD)
```

```{r}
set.seed(1)
#train-test split ratio 0.8
id <- createDataPartition(CHD$TenYearCHD, p = 0.8, list = FALSE)

train<-CHD[id, ]
test<-CHD[-id, ]
```

### 2a. Linear Regression Classification
```{r}
train_y <-train$TenYearCHD
test_y <- test$TenYearCHD
train_x <- train[, -16]
test_x <- test[, -16]

linearModel <- lm(train$TenYearCHD ~ ., train)
result <- data.table(predict(linearModel, test_x))
linear_results <- result[,round(V1)]

accuracy_lm <- linear_results + test_y #0 = True negative, #2 = True positive
accuracy <- 1 - (sum(accuracy_lm == 1)/length(accuracy_lm))

cat("The linear regression model accuracy is", accuracy)
```

### 2b. Linear Regression with Lasso Classification
```{r}
# Create formula
formula <- as.formula(TenYearCHD ~ .)

# Training set modeling 
train.matrix <- model.matrix(formula, train)[, -1]
train_y <- train$TenYearCHD
fit <- cv.glmnet(train.matrix, train_y, family = "binomial", alpha = 1, nfolds = 10)
# plot 
plot(fit)
# Create testing matrices
test.matrix <- model.matrix(formula, test) [, -1]
```

```{r}
coef(fit,s=fit$lambda.min)
```

```{r}
# Predicting test data

test.predictions <- predict(fit, test.matrix, s = fit$lambda.min, type = "response") 

##F1 score, select cutoff which makes the F1 score largest
Fmeasure <- c()
cutoffs <- seq(0.05, 0.85, 0.01)
for(cutoff in cutoffs) {

predicted.CHD <- ifelse(test.predictions > cutoff, 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")

Fmeasure <- c(Fmeasure,  cmat$byClass[7] )
}

cutoffs[which.max(Fmeasure)]
#0.15

predicted.CHD <- ifelse(test.predictions > cutoffs[which.max(Fmeasure)], 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")
cmat
#F1 score
cmat$byClass[7]
c<-roc.curve( as.numeric(predicted.CHD),as.numeric(test$TenYearCHD), curve = TRUE)
plot(c)
```

### 3. Logistic Classification 
```{r}
#use variables selected by lasso
coefs <- coef(fit,s=fit$lambda.min)
variables <- which(coefs !=0)

selectvariables <- names(coefs[variables,])[-1]
selectvariables

train2<-train.matrix[,selectvariables]
test2<-test.matrix[,selectvariables]

newtrain <- data.frame(train2, TenYearCHD = train$TenYearCHD)
newtest <- data.frame(test2, TenYearCHD = test$TenYearCHD)

fit2 <- glm(TenYearCHD ~ ., data = newtrain, family = binomial(link = "logit"))
summary(fit2)

# Predicting test data

test.predictions <- predict(fit2, newtest,  type = "response") 


predicted.CHD <- ifelse(test.predictions > cutoffs[which.max(Fmeasure)], 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")
cmat
#F1 score
cmat$byClass[7]
c<-roc.curve( as.numeric(predicted.CHD),as.numeric(test$TenYearCHD), curve = TRUE)
plot(c)

#use full data
fit3 <- glm(TenYearCHD ~ ., data = train, family = binomial(link = "logit"))
summary(fit3)

# Predicting test data

test.predictions <- predict(fit3, test,  type = "response") 


predicted.CHD <- ifelse(test.predictions > cutoffs[which.max(Fmeasure)], 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")
cmat
#F1 score
cmat$byClass[7]
c<-roc.curve( as.numeric(predicted.CHD),as.numeric(test$TenYearCHD), curve = TRUE)
plot(c)

#use  backward selection with AIC criterion

fit4 <- step(fit3,trace = F)
summary(fit4)
# Predicting test data

test.predictions <- predict(fit4, test,  type = "response") 


predicted.CHD <- ifelse(test.predictions > cutoffs[which.max(Fmeasure)], 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")
cmat

c<-roc.curve( as.numeric(predicted.CHD),as.numeric(test$TenYearCHD), curve = TRUE)
plot(c)

#all logistic models are similar
```

### 4. KNN - K-Nearest Neighbors 
```{r}
set.seed(1)
#set  10-folds cross validation 
ctrl <- trainControl(method = "cv", 
                     number = 10)
#KNN for k-nearest neighbors 

#check parameters tuning results
m <- train(factor(TenYearCHD) ~ ., data = train, 
           method = "knn",
           trControl = ctrl)

m
plot(m)

test.predictions <- predict(m, test,  type = "prob")[,2]

predicted.CHD <- ifelse(test.predictions > cutoffs[which.max(Fmeasure)], 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")
cmat

c<-roc.curve( as.numeric(predicted.CHD),as.numeric(test$TenYearCHD), curve = TRUE)
plot(c)
```

### 5. Random Forest
```{r}
set.seed(1)
#set  10-folds cross validation 
ctrl <- trainControl(method = "cv", 
                     number = 10)
#rf for random forest

#check parameters tuning results
m <- train(factor(TenYearCHD) ~ ., data = train, 
           method = "rf",
           trControl = ctrl)

m

plot(m)

#variable important plot
plot(varImp(m))

test.predictions <- predict(m, test,  type = "prob")[,2]


predicted.CHD <- ifelse(test.predictions > cutoffs[which.max(Fmeasure)], 1, 0)
cmat <- confusionMatrix(as.factor(predicted.CHD), as.factor(test$TenYearCHD), positive = "1")
cmat

c<-roc.curve( as.numeric(predicted.CHD),as.numeric(test$TenYearCHD), curve = TRUE)
plot(c)
```

### 6.Decision Trees
```{r}
library(rpart)
library(rpart.plot)

train$TenYearCHD<-as.factor(train$TenYearCHD)

fit <- rpart(TenYearCHD~., data = train, method = 'class')
rpart.plot(fit, extra = 106)
```

```{r}
predict_unseen <-predict(fit, test, type = 'class')
```
